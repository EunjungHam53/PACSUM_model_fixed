Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections Abstract We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.
Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.
We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg- Kirkpatrick et al., 2010).
Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.
Conclusion We have shown the efficacy of graph-based label propagation for projecting part-of-speech information across languages.
Because we are interested in applying our techniques to languages for which no labeled resources are available, we paid particular attention to minimize the number of free parameters and used the same hyperparameters for all language pairs.
Our results suggest that it is possible to learn accurate POS taggers for languages which do not have any annotated data, but have translations into a resource-rich language.
Our results outperform strong unsupervised baselines as well as approaches that rely on direct projections, and bridge the gap between purely supervised and unsupervised POS tagging models.
Subramanya et al.
's model was extended by Das and Petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers.
Fortunately, some recently proposed POS taggers, such as the POS tagger of Das and Petrov (2011), rely only on labeled training data for English and the same kind of parallel text in our approach.
Applications have ranged from domain adaptation of part-of-speech (POS) taggers (Subramanya et al., 2010), unsupervised learning of POS taggers by using bilingual graph-based projections (Das and Petrov, 2011), and shallow semantic parsing for unknown predicates (Das and Smith, 2011).
Following Das and Petrov (2011) and Subramanya et al.
(2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics.
Sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type are unavailable (e.g., Das and Petrov, 2011).
Specifically, by replacing fine-grained language-specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available.
Below, we extend this approach to universal parsing by adding cross-lingual word cluster features.